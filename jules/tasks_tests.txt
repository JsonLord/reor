### **1. Estimation of Project Scope (1-10): 9**
- **Core Parts**:
  - **Backend**: OpenAI-compatible LLM integration (BLABLADOR API), FastAPI/Flask wrapper for Reor APIs, and embedding/rag logic.
  - **Frontend**: Gradio UI (retained from Reor) with AI assistant features.
  - **Deployment**: Dockerized Hugging Face Space with API forwarding (`/api/*` → FastAPI, `/` → Gradio).
  - **Security**: API key validation, rate limiting, and input sanitization.
  - **Monitoring**: Logging, health checks, and alerting.

---

### **2. Project Description**
**Vision**:
Reor will be deployed on Hugging Face Spaces as an **AI-powered personal knowledge management app** with a focus on **local-first RAG and semantic search**, while enabling remote LLM inference via the **BLABLADOR API**. The app will retain its core functionality (chunking, embedding, Q&A) but expose APIs for external management.

**Concrete Goals**:
- **LLM Integration**: Use BLABLADOR’s `alias-large` model via OpenAI-compatible API (`api.helmholtz-blablador.fz-juelich.de/v1`).
- **API Exposure**: Deploy `/api/query`, `/api/search`, and `/api/embeddings` endpoints externally.
- **Gradio UI**: Keep the Obsidian-like editor at `harvesthealth-magnetic-ui.hf.space:7860`.
- **Local Persistence**: LanceDB remains for vector storage.
- **Security**: Validate `BLABLADOR_API_KEY` on startup and enforce rate limits.

**Future Use Cases**:
- **Enterprise Knowledge Bases**: Integration with corporate document repositories.
- **Research Tools**: Collaborative note-taking with AI-assisted analysis.
- **Hugging Face Embeddings**: Export LanceDB embeddings to HF Hub.

**Future Integrations**:
- **External APIs**: Auth0/OAuth for user management.
- **Vector DBs**: Weaviate/Pinecone for scaling.
- **Plugins**: GitHub/GitLab sync for code-heavy notes.

---

### **3. External Projects/APIs Integrated**
| Component               | Role                                                                 | Docs/Repo                                                                 |
|-------------------------|----------------------------------------------------------------------|---------------------------------------------------------------------------|
| **BLABLADOR API**       | OpenAI-compatible LLM (`alias-large`) for RAG/Q&A.                   | `https://api.helmholtz-blablador.fz-juelich.de/v1`                       |
| **LanceDB**             | Vector database for embeddings/semantic search.                      | `https://github.com/lancedb/lancedb`                                      |
| **Transformers.js**     | Local embeddings (fallback if BLABLADOR fails).                     | `https://github.com/xenova/transformers.js`                              |
| **FastAPI/Flask**       | API layer for `/api/*` endpoints.                                    | `https://fastapi.tiangolo.com/`                                          |
| **Gradio**              | UI framework (port `7860`).                                           | `https://github.com/gradio-app/gradio`                                    |
| **Hugging Face Spaces** | Hosting with port forwarding (`/api/*` → FastAPI).                  | `https://huggingface.co/spaces/docs`                                     |

---

### **4. Components & Subtasks**
#### **4.1 Core Components**
1. **Backend (FastAPI)**:
   - Wraps Reor’s RAG/embedding logic.
   - Routes:
     - `/api/query` → LLM Q&A (BLABLADOR).
     - `/api/embeddings` → Generate/text embeddings.
     - `/api/search` → LanceDB semantic search.
2. **Frontend (Gradio)**:
   - Obsidian-like markdown editor + AI sidebar (summaries/related notes).
3. **Docker/Nginx**:
   - Reverse proxy for `/api/*` → FastAPI (`8000`), `/` → Gradio (`7860`).
4. **Security Layer**:
   - Validate `BLABLADOR_API_KEY` from Hugging Face env vars.
   - Rate limiter (100 reqs/hour).
5. **LanceDB**:
   - Store/chunk notes, generate embeddings.

#### **4.2 Subtasks per Component**
##### **Backend (FastAPI)**
- **Architecture**:
  - **Security**: JWT for API auth (optional) + key validation.
  - **Functionality**:
    - Endpoint `/api/query`: Accepts `text` → returns LLM answer (BLABLADOR).
    - Endpoint `/api/embeddings`: Chunks text → embeddings (BLABLADOR or Transformers.js).
    - Endpoint `/api/search`: Query LanceDB → return top-k similar notes.
  - **Interaction**:
    - FastAPI ↔ Gradio (WebSocket for real-time AI suggestions).
    - FastAPI ↔ BLABLADOR (HTTP POST for LLM calls).
- **Integration**:
  - Use `requests` to call BLABLADOR API (openai-compatible).
  - LanceDB: `lancedb.connect()` for local storage.

##### **Frontend (Gradio)**
- **Adaptations**:
  - Add Gradio `gr.Interface` for AI sidebar (toggle for summaries/related notes).
  - Integrate with FastAPI via `requests.get("http://localhost:8000/api/query")`.
- **New Features**:
  - **Auto-summarize**: Send note → `/api/embeddings` → BLABLADOR summary.
  - **Related Notes**: Query LanceDB → display top-3 matches.

##### **Docker/Nginx**
- **Dockerfile**:
  - Multi-stage: Python base → install FastAPI/Gradio/LanceDB.
  - Expose ports `8000` (API) and `7860` (Gradio).
- **Nginx Config**:
  ```nginx
  server {
      listen 80;
      location /api/ { proxy_pass http://localhost:8000; }
      location / { proxy_pass http://localhost:7860; }
  }
  ```

##### **LanceDB**
- **Cloning/Setup**:
  - Clone repo: `git clone https://github.com/lancedb/lancedb.git`.
  - Use `lancedb init --path ./data` for local storage.
- **Integration**:
  - Chunk notes → embed with BLABLADOR/Transformers.js → store in LanceDB.
  - Query with `lancedb.search()` for semantic search.

#### **4.3 Tests per Component**
| Component       | Test Description                                                                 | Success Criteria                                                                 |
|-----------------|---------------------------------------------------------------------------------|----------------------------------------------------------------------------------|
| **Backend**     | Send POST to `/api/query` with `text="Summarize my notes"` → BLABLADOR response. | 200 OK + valid JSON answer.                                                     |
|                 | Call `/api/embeddings` with sample text → return embedding vector.             | Shape `(1, 768)` (for `alias-large`).                                            |
| **Frontend**    | Toggle Gradio AI sidebar → auto-summary appears.                              | UI updates with BLABLADOR summary.                                               |
| **Docker**      | `curl http://localhost:8000/api/health` → `{"status": "ok"}`.                  | Container runs, ports exposed.                                                   |
| **LanceDB**     | Insert 10 notes → search for "AI" → return top-3 matches.                      | 3 notes with similarity scores > 0.7.                                            |

---

### **5. Full Pipeline Test**
**Description**:
Test the end-to-end flow:
1. User uploads a markdown note via Gradio UI.
2. Backend chunks/embeds the note (BLABLADOR).
3. User queries "What are my AI notes?" via Gradio.
4. Backend:
   - Chunks query → searches LanceDB → retrieves top-3 notes.
   - Passes context to BLABLADOR for Q&A.
5. Gradio displays LLM answer + related notes.

**Mock Input**:
```markdown
# AI Notes
- Transformers.js enables local LLMs.
- BLABLADOR is an OpenAI-compatible API.
```
**Mock Query**: `"Explain BLABLADOR’s role in Reor."`
**Expected Output**:
```json
{
  "answer": "BLABLADOR provides OpenAI-compatible LLM inference for Reor’s Q&A system...",
  "related_notes": [
    {"id": "ai_notes", "score": 0.95},
    {"id": "ollama_integration", "score": 0.82}
  ]
}
```

---
### **6. API Endpoints**
| Endpoint               | Method | Description                                  | Example Request Body                          | Success Response                          |
|------------------------|--------|----------------------------------------------|-----------------------------------------------|-------------------------------------------|
| `/api/embeddings`      | POST   | Generate embeddings for text.               | `{"text": "Sample note"}`                    | `{"embeddings": [0.1, -0.2, ...]}`      |
| `/api/query`           | POST   | RAG-powered Q&A with BLABLADOR.            | `{"text":