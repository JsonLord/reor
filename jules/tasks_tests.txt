### **3. Other Projects or API Endpoints to be Integrated**

1. **BLABLADOR API (LLM Provider)**
   - **Endpoint**: [`https://api.helmholtz-blablador.fz-juelich.de/v1`](https://api.helmholtz-blablador.fz-juelich.de/v1)
   - **Model**: `alias-large` (OpenAI-compatible)
   - **Integration Purpose**:
     - Replace Ollama/OpenAI logic in Reor’s backend.
     - Power RAG, semantic search, and Q&A features.
   - **API Docs**: Assume OpenAI-compatible (e.g., `chat/completions`, `embeddings` endpoints).
   - **Authentication**:
     - `BLABLADOR_API_KEY` from Hugging Face Space secrets.

2. **LanceDB (Vector Database)**
   - **Purpose**: Store and query embeddings for semantic search.
   - **Integration Status**: Already used in Reor (no changes needed).

3. **Hugging Face Spaces Deployment**
   - **Endpoint**: `harvesthealth-magnetic-ui.hf.space`
   - **Port Forwarding**: Expose internal port `7860` via Hugging Face.
   - **Frontend Options**:
     - Native Reor UI (if UI logic is preserved).
     - Gradio/Streamlit wrapper (if replacing frontend).

4. **Ollama (Deprecated)**
   - **Current Use**: Local LLM hosting (replaced by BLABLADOR API).
   - **Action**: Remove Ollama dependencies; proxy BLABLADOR API calls.

---
### **4. Components to Build & Interactions**

#### **Core Components**
| **Component**               | **Purpose**                                                                 | **Dependencies**                     |
|-----------------------------|-----------------------------------------------------------------------------|--------------------------------------|
| **LLM Service (`llm-service`)** | Bridge BLABLADOR API to Reor’s RAG/Q&A logic.                              | BLABLADOR API, LanceDB (embeddings)  |
| **Vector Database (LanceDB)**  | Store note embeddings for semantic search.                                  | Local file storage                   |
| **API Proxy (`proxy.py`)**      | Forward Hugging Face Space requests to Reor’s internal APIs.             | FastAPI/Flask                       |
| **Docker Container**            | Package Reor + proxy for Hugging Face deployment.                         | Node.js, FastAPI                     |
| **Hugging Face Space**         | Host the app with port forwarding and secrets management.                  | Dockerfile, `BLABLADOR_API_KEY`      |

---
#### **4.1 Subtasks by Component**
##### **1. LLM Service Adaptation**
- **Architecture**:
  - Modify `src/services/llm.ts` to support BLABLADOR’s OpenAI endpoint.
  - Add error handling for API rate limits/keys.
  - Cache embeddings locally (avoid redundant API calls).
- **Interaction Endpoints**:
  - `/chat/completions` → BLABLADOR’s API.
  - `/embeddings` → Send text chunks to BLABLADOR for vectorization.
- **Security**:
  - Validate `BLABLADOR_API_KEY` from environment variables.
  - Sanitize user prompts to prevent injection.

##### **2. API Proxy (`proxy.py`)**
- **Architecture**:
  - FastAPI/Flask middleware to forward requests to Reor’s port (`7860`).
  - Add authentication middleware (API keys or Hugging Face OAuth).
- **Endpoints**:
  - `/notes` → `http://localhost:7860/notes`
  - `/qa` → `http://localhost:7860/qa`
  - `/search` → `http://localhost:7860/search`
- **Security**:
  - Require `Authorization` header for write endpoints (`POST /notes`, `POST /qa`).

##### **3. Docker Configuration**
- **Dockerfile**:
  - Multi-stage build: Node.js for Reor + Python (FastAPI) for proxy.
  - Expose port `7860` and mount `BLABLADOR_API_KEY` as secret.
- **Build Protocol**:
  ```dockerfile
  FROM node:18 AS reor
  WORKDIR /app
  COPY package*.json ./
  RUN npm install
  COPY . .
  EXPOSE 7860

  FROM python:3.9 AS proxy
  WORKDIR /proxy
  COPY requirements.txt .
  RUN pip install -r requirements.txt
  COPY proxy.py .
  CMD ["uvicorn", "proxy:app", "--host", "0.0.0.0", "--port", "7860"]
  ```
- **Interaction**:
  - Proxy container forwards requests to Reor’s Node.js service running on the same network.

##### **4. Hugging Face Space Setup**
- **Secrets**:
  - Add `BLABLADOR_API_KEY` in Space settings → Secrets.
- **Port Forwarding**:
  - Map `7860` → `harvesthealth-magnetic-ui.hf.space`.
- **Deployment**:
  - Use `Dockerfile` from the GH repo; no GPU required.

---
#### **4.2 Integration Judgments**
| **External Code/Service** | **Integration Feasibility** | **Notes**                                                                 |
|---------------------------|----------------------------|---------------------------------------------------------------------------|
| BLABLADOR API             | Full Integration            | OpenAI-compatible; no code mirroring needed.                             |
| Ollama                    | Deprecated                  | Replace all local model calls with BLABLADOR API.                         |
| Transformers.js           | Retained                   | Only used for embeddings; BLABLADOR API handles LLM logic.                |
| LanceDB                   | Retained                   | No changes needed; embeddings remain local.                              |
| FastAPI/Flask Proxy       | Full Integration            | Acts as a reverse proxy for Reor’s Node.js backend.                       |
| Hugging Face Spaces       | Full Integration            | Docker + port forwarding; no code changes to Reor’s UI.                  |

---
### **4.3 Tests per Component**
#### **LLM Service**
- **Test 1**: Verify BLABLADOR API calls return valid completions.
  - **Input**: `{"model": "alias-large", "messages": [{"role": "user", "content": "Summarize my notes on AI ethics"}]}`
  - **Success**: No `401`/`429` errors; response includes `choices[0].message.content`.
- **Test 2**: Test RAG with retrieved context.
  - **Input**: Query + 3 retrieved notes (from LanceDB).
  - **Success**: Response cites specific notes in the corpus.
- **Test 3**: Validate embeddings.
  - **Input**: `["test note text"]` → BLABLADOR’s `/embeddings` endpoint.
  - **Success**: Returns a 1536-dim vector (match BLABLADOR’s model).

#### **API Proxy**
- **Test 1**: Forward `/notes` to Reor.
  - **Request**: `GET https://hf.space/notes` → Proxy → `GET http://localhost:7860/notes`.
  - **Success**: Returns list of notes (200 status).
- **Test 2**: Authenticate API key.
  - **Request**: `POST /qa` without `Authorization` header.
  - **Success**: Returns `401 Unauthorized`.
- **Test 3**: Validate Q&A endpoint.
  - **Request**: `POST /qa` with `{"query": "Explain vector search"}`.
  - **Success**: Returns RAG response using `alias-large`.

#### **Docker Deployment**
- **Test 1**: Local build + run.
  - **Command**: `docker run -p 7860:7860 reor-hf`.
  - **Success**: `curl http://localhost:7860/notes` returns notes.
- **Test 2**: Proxy routes work.
  - **Command**: `curl http://localhost:7860/search?q=AI`.
  - **Success**: Returns semantic search results.

#### **Hugging Face Space**
- **Test 1**: Space URL accessibility.
  - **Action**: Visit `harvesthealth-magnetic-ui.hf.space`.
  - **Success**: UI loads (or Gradio interface if used).
- **Test 2**: External API calls.
  - **Request**: `curl -H "Authorization: Bearer KEY" https://hf.space/qa -d '{"query": "test"}'`.
  - **Success**: Returns `alias-large` response.

---
### **5. Full Pipeline Test**
#### **Test Description**
Simulate a user workflow: **Add a note → Query with RAG → Retrieve related notes**.

#### **Mock-Up Input Data**
1. **Notes Directory**:
   ```
   /notes/
     note1.md: "AI ethics emphasizes fairness."
     note2.md: "Bias in LLMs is a key concern."
   ```
2. **Test Steps**:
   - **Step 1**: Index notes via LanceDB (done on startup).
   - **Step 2**: User asks: `"What are the risks of biased AI?"`
     - **API Call**: `POST /qa` → Proxy → BLABLADOR API + LanceDB retrieval.
   - **Step 3**: System responds